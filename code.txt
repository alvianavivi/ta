sudo apt-get update
sudo apt-get install -y python3-dev python3-pip python3-numpy python3-opencv libatlas-base-dev libjasper-dev libqtgui4 libqt4-test libhdf5-dev libhdf5-103

git clone https://github.com/google/mediapipe.git

cd mediapipe
mkdir build && cd build
cmake .. -DCMAKE_BUILD_TYPE=Release -DWITH_GPU=OFF -DWITH_TFLITE_GPU_DELEGATE=OFF
make -j4
sudo make install


wget https://github.com/bazelbuild/bazel/releases/download/4.1.0/bazel-4.1.0-installer-linux-arm64.sh
chmod +x bazel-4.1.0-installer-linux-arm64.sh
sudo ./bazel-4.1.0-installer-linux-arm64.sh --user
echo 'export PATH="$HOME/bin:$PATH"' >> ~/.bashrc
source ~/.bashrc


curl https://bazel.build/bazel-release.pub.gpg | sudo apt-key add -
echo "deb [arch=armhf] https://storage.googleapis.com/bazel-apt stable jdk1.8" | sudo tee /etc/apt/sources.list.d/bazel.list



===========
import cv2
import mediapipe as mp

mp_drawing = mp.solutions.drawing_utils
mp_face = mp.solutions.face_detection.FaceDetection(model_selection=1,min_detection_confidence=0.5)
cap=cv2.VideoCapture(0)
width=640
height=480


def obj_data(img):
    image_input = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    results = mp_face.process(image_input)
    if not results.detections:
        print("NO FACE")
    else:    
         for detection in results.detections:
             bbox = detection.location_data.relative_bounding_box
             print(bbox)
             x, y, w, h = int(bbox.xmin*width), int(bbox.ymin * height), int(bbox.width*width),int(bbox.height*height)
             cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)
             
            
while True:
    ret,frame=cap.read()
    frame=cv2.resize(frame,(640,480))
    obj_data(frame)
    cv2.imshow("FRAME",frame)
    if cv2.waitKey(1)&0xFF==27:
        break
cap.release()
cv2.destroyAllWindows()
==================


    for label in os.listdir(train_dir):
    label_dict[label] = len(label_dict)
    label_path = os.path.join(train_dir, label)
    for img_path in os.listdir(label_path):
        image = cv2.imread(os.path.join(label_path, img_path))
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        results_detection = face_detection.process(image_rgb)
        detections = results_detection.detections
        if detections is not None:
            for detection in detections:
                mp_drawing.draw_detection(image, detection)
            results_mesh = face_mesh.process(image_rgb)
            multi_face_landmarks = results_mesh.multi_face_landmarks
            if multi_face_landmarks is not None:
                for face_landmarks in multi_face_landmarks:
                    landmarks = []
                    for landmark in face_landmarks.landmark:
                        landmarks.append(landmark.x)
                        landmarks.append(landmark.y)
                        landmarks.append(landmark.z)
                    landmarks = np.array(landmarks, dtype=np.float32)
                    label_id = label_dict[label]
                    images.append(landmarks)
                    labels.append(label_id)